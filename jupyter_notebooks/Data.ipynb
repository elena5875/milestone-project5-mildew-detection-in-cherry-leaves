{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12669454-fb7a-4e7e-b778-1bc25ea6a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.12.tar.gz (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /workspace/.pip-modules/lib/python3.8/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle) (2.31.0)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: bleach in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->kaggle) (3.7)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.12-py3-none-any.whl size=102969 sha256=6433206665d3402478b66b29b49b446eea2f3a4647769682fd048b78e578a836\n",
      "  Stored in directory: /home/gitpod/.cache/pip/wheels/a0/87/83/f9893bb1660a03ca5808b7429e77808120f091569651323dd1\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, tqdm, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.6.12 python-slugify-8.0.4 text-unidecode-1.3 tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "#installing Kaggle\n",
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f63680e-dce9-4e99-9f3b-d7a584fdc990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/codeinstitute/cherry-leaves\n",
      "License(s): unknown\n",
      "Downloading cherry-leaves.zip to /workspace/milestone-project5-mildew-detection-in-cherry-leaves/jupyter_notebooks\n",
      " 91%|██████████████████████████████████▌   | 50.0M/55.0M [00:01<00:00, 46.3MB/s]\n",
      "100%|██████████████████████████████████████| 55.0M/55.0M [00:01<00:00, 39.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "#downloading kaggle dataset for cherry leaves\n",
    "!kaggle datasets download -d codeinstitute/cherry-leaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45aa348f-d516-47ee-9b11-66eb2728f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzipping the file\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"cherry-leaves.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"cherry-leaves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9b0c0ad-af97-4d5d-8964-2c3c90d3714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/milestone-project5-mildew-detection-in-cherry-leaves/jupyter_notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c69423-bc6d-4f93-a8b6-ae3c182a01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing the image file\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define directory paths\n",
    "dataset_dirs = [\"./cherry-leaves/cherry-leaves-folder/healthy\", \"./cherry-leaves/cherry-leaves-folder/powdery_mildew\"]\n",
    "output_dir = \"./clean_data\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to resize images and save them\n",
    "def resize_and_save_image(image_path, output_path, new_size=(50, 50)):\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_image = image.resize(new_size)\n",
    "    \n",
    "    # Save resized image\n",
    "    resized_image.save(output_path)\n",
    "\n",
    "# Iterate through dataset directories\n",
    "for dataset_dir in dataset_dirs:\n",
    "    # Get category name from directory\n",
    "    category = os.path.basename(dataset_dir)\n",
    "    \n",
    "    # Output directory for the current category\n",
    "    output_category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(output_category_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through files in the dataset directory\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.lower().endswith((\".jpeg\", \".jpg\")):\n",
    "            # Input and output paths\n",
    "            input_path = os.path.join(dataset_dir, file)\n",
    "            output_path = os.path.join(output_category_dir, file)\n",
    "            \n",
    "            # Resize image and save\n",
    "            resize_and_save_image(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9c9787-ae54-494f-a1f6-4abf716964d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /workspace/.pip-modules/lib/python3.8/site-packages (10.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364f594b-bff8-4690-bc9f-af15c24d6d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into training, validation, and test sets successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define directories\n",
    "clean_data_dir = './clean_data/'\n",
    "train_dir = './data_split/train/'\n",
    "val_dir = './data_split/validation/'\n",
    "test_dir = './data_split/test/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# List all the images in the clean_data directory\n",
    "all_images = os.listdir(clean_data_dir)\n",
    "random.shuffle(all_images)  # Shuffle the list randomly\n",
    "\n",
    "# Define the size of each set\n",
    "train_size = int(0.7 * len(all_images))  # 70% for training\n",
    "val_size = int(0.15 * len(all_images))  # 15% for validation\n",
    "test_size = len(all_images) - train_size - val_size  # Remaining for testing\n",
    "\n",
    "# Split the images into training, validation, and test sets\n",
    "train_images = all_images[:train_size]\n",
    "val_images = all_images[train_size:train_size + val_size]\n",
    "test_images = all_images[train_size + val_size:]\n",
    "\n",
    "# Move images to their respective directories\n",
    "for image in train_images:\n",
    "    shutil.move(os.path.join(clean_data_dir, image), os.path.join(train_dir, image))\n",
    "\n",
    "for image in val_images:\n",
    "    shutil.move(os.path.join(clean_data_dir, image), os.path.join(val_dir, image))\n",
    "\n",
    "for image in test_images:\n",
    "    shutil.move(os.path.join(clean_data_dir, image), os.path.join(test_dir, image))\n",
    "\n",
    "print(\"Dataset split into training, validation, and test sets successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640386cd-d768-4be8-aa34-afcc64bc583a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
